# MCP-Coordinator Configuration
# ==============================

# Path to MCP server configuration file
# Default: ./mcp.json in project root
# Priority: Explicit path > MCP_JSON env > ./mcp_servers.json
# MCP_JSON=/path/to/your/mcp_servers.json

# Code executor type: local, docker, e2b, modal, wasm
# Recommended: docker (best security/performance balance)
# Default: local
MCP_EXECUTOR_TYPE=local

# =============================================================================
# Ollama Configuration (Cheapest Local Option)
# =============================================================================

# Ollama API endpoint
OLLAMA_API_BASE=http://localhost:11434

# Ollama model to use
# Local models: llama3.2:3b, qwen2.5-coder:7b, etc.
# Cloud models (requires auth): qwen3-coder:480b-cloud, gpt-oss:120b-cloud
OLLAMA_MODEL=qwen3:latest

# =============================================================================
# Docker Executor Configuration (when MCP_EXECUTOR_TYPE=docker)
# =============================================================================

# Docker image for execution
# Recommended: python:3.12-slim (lightweight, secure)
DOCKER_IMAGE=python:3.12-slim

# Memory limit for Docker container
DOCKER_MEM_LIMIT=512m

# CPU quota (50000 = 50% of one core)
DOCKER_CPU_QUOTA=50000

# =============================================================================
# Cloud Services (Optional)
# =============================================================================

# HuggingFace token for cloud models
# Required for: InferenceClientModel, hosted models
# Get token: https://huggingface.co/settings/tokens
# HF_TOKEN=hf_xxxxxxxxxxxxxxxxxxxxx

# E2B API key (when MCP_EXECUTOR_TYPE=e2b)
# Get key: https://e2b.dev/
# E2B_API_KEY=your_e2b_key_here

# Modal API credentials (when MCP_EXECUTOR_TYPE=modal)
# Get token: https://modal.com/settings
# MODAL_TOKEN_ID=your_token_id
# MODAL_TOKEN_SECRET=your_token_secret

# OpenAI API key (for OpenAI models via LiteLLM)
# OPENAI_API_KEY=sk-xxxxxxxxxxxxxxxxxxxxx

# Anthropic API key (for Claude models via LiteLLM)
# ANTHROPIC_API_KEY=sk-ant-xxxxxxxxxxxxxxxxxxxxx

# =============================================================================
# Advanced Settings
# =============================================================================

# Maximum execution time (seconds)
# MAX_EXECUTION_TIME=30

# Enable network isolation (Linux only)
# NETWORK_ISOLATION=false

# Workspace directory
# WORKSPACE_DIR=./workspace

# Tools output directory
# TOOLS_OUTPUT_DIR=./mcp_tools
